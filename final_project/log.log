Number of people in the dataset: 145
Fraction of POIs in the test dataset: 0.222222222222
salary selector score: 21.5094211121 (p = 1.07812132641e-05 )
bonus selector score: 20.8946296894 (p = 1.4038642155e-05 )
from_this_person_to_poi selector score: 0.0480500300844 (p = 0.826943085158 )
from_poi_to_this_person selector score: 5.59192825481 (p = 0.0199938789973 )
fraction_from_poi selector score: 11.3159743154 (p = 0.00109408097147 )
fraction_to_poi selector score: 1.68451953168 (p = 0.197340800285 )
log_total_emails_ratio selector score: 12.3767319586 (p = 0.000658140755409 )
shared_receipt_with_poi selector score: 10.4323474239 (p = 0.00168092970998 )
director_fees selector score: 1.82261389523 (p = 0.180081028704 )
deferral_payments selector score: 0.029462125634 (p = 0.864066720197 )
log_poi_emails_ratio selector score: 3.48655390159 (p = 0.0648278974436 )
Selected indexes: ['salary', 'bonus', 'fraction_from_poi', 'log_total_emails_ratio', 'shared_receipt_with_poi']
# GaussianNB :: Tuning parameters for precision
# Best parameters set found on training set:
{}
# Grid scores on testing set:
0.763 (+/-0.193) for {}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.90      0.93      0.91        40
        1.0       0.00      0.00      0.00         4

avg / total       0.82      0.84      0.83        44

# DecisionTreeClassifier :: Tuning parameters for precision
# Best parameters set found on training set:
{'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8}
# Grid scores on testing set:
0.878 (+/-0.220) for {'min_samples_split': 10, 'criterion': 'gini', 'max_depth': 8}
0.844 (+/-0.247) for {'min_samples_split': 6, 'criterion': 'gini', 'max_depth': 8}
0.835 (+/-0.289) for {'min_samples_split': 4, 'criterion': 'gini', 'max_depth': 8}
0.905 (+/-0.174) for {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8}
0.862 (+/-0.261) for {'min_samples_split': 10, 'criterion': 'gini', 'max_depth': 6}
0.860 (+/-0.211) for {'min_samples_split': 6, 'criterion': 'gini', 'max_depth': 6}
0.862 (+/-0.268) for {'min_samples_split': 4, 'criterion': 'gini', 'max_depth': 6}
0.883 (+/-0.266) for {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 6}
0.863 (+/-0.259) for {'min_samples_split': 10, 'criterion': 'gini', 'max_depth': 4}
0.845 (+/-0.246) for {'min_samples_split': 6, 'criterion': 'gini', 'max_depth': 4}
0.851 (+/-0.254) for {'min_samples_split': 4, 'criterion': 'gini', 'max_depth': 4}
0.863 (+/-0.262) for {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 4}
0.784 (+/-0.213) for {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 8}
0.871 (+/-0.219) for {'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 8}
0.857 (+/-0.254) for {'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': 8}
0.863 (+/-0.261) for {'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 8}
0.784 (+/-0.213) for {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 6}
0.870 (+/-0.220) for {'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 6}
0.858 (+/-0.252) for {'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': 6}
0.830 (+/-0.274) for {'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 6}
0.764 (+/-0.161) for {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 4}
0.844 (+/-0.246) for {'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 4}
0.889 (+/-0.229) for {'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': 4}
0.899 (+/-0.168) for {'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 4}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.92      0.90      0.91        40
        1.0       0.20      0.25      0.22         4

avg / total       0.86      0.84      0.85        44

# LogisticRegression :: Tuning parameters for precision
# Best parameters set found on training set:
{'C': 100}
# Grid scores on testing set:
0.792 (+/-0.251) for {'C': 1000}
0.807 (+/-0.216) for {'C': 100}
0.780 (+/-0.195) for {'C': 10}
0.782 (+/-0.189) for {'C': 5}
0.743 (+/-0.129) for {'C': 1}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.91      1.00      0.95        40
        1.0       0.00      0.00      0.00         4

avg / total       0.83      0.91      0.87        44

# SVC :: Tuning parameters for precision
# Best parameters set found on training set:
{'kernel': 'rbf', 'C': 100, 'gamma': 0.5}
# Grid scores on testing set:
0.795 (+/-0.219) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.05}
0.811 (+/-0.257) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.05}
0.789 (+/-0.236) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.05}
0.795 (+/-0.219) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.1}
0.893 (+/-0.213) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.1}
0.777 (+/-0.202) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.1}
0.795 (+/-0.219) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.2}
0.889 (+/-0.217) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.2}
0.792 (+/-0.251) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.2}
0.795 (+/-0.219) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.5}
0.817 (+/-0.263) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.5}
0.868 (+/-0.175) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.5}
0.795 (+/-0.219) for {'kernel': 'linear', 'C': 1000, 'gamma': 1.0}
0.839 (+/-0.236) for {'kernel': 'rbf', 'C': 1000, 'gamma': 1.0}
0.825 (+/-0.238) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 1.0}
0.795 (+/-0.219) for {'kernel': 'linear', 'C': 1000, 'gamma': 10.0}
0.845 (+/-0.255) for {'kernel': 'rbf', 'C': 1000, 'gamma': 10.0}
0.735 (+/-0.123) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 10.0}
0.792 (+/-0.226) for {'kernel': 'linear', 'C': 100, 'gamma': 0.05}
0.777 (+/-0.202) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}
0.780 (+/-0.195) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.05}
0.792 (+/-0.226) for {'kernel': 'linear', 'C': 100, 'gamma': 0.1}
0.777 (+/-0.202) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}
0.780 (+/-0.195) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.1}
0.792 (+/-0.226) for {'kernel': 'linear', 'C': 100, 'gamma': 0.2}
0.806 (+/-0.243) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.2}
0.774 (+/-0.212) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.2}
0.792 (+/-0.226) for {'kernel': 'linear', 'C': 100, 'gamma': 0.5}
0.894 (+/-0.224) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.5}
0.834 (+/-0.202) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.5}
0.792 (+/-0.226) for {'kernel': 'linear', 'C': 100, 'gamma': 1.0}
0.859 (+/-0.249) for {'kernel': 'rbf', 'C': 100, 'gamma': 1.0}
0.807 (+/-0.217) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 1.0}
0.792 (+/-0.226) for {'kernel': 'linear', 'C': 100, 'gamma': 10.0}
0.850 (+/-0.265) for {'kernel': 'rbf', 'C': 100, 'gamma': 10.0}
0.735 (+/-0.123) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 10.0}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 10, 'gamma': 0.05}
0.742 (+/-0.127) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.05}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 10, 'gamma': 0.1}
0.756 (+/-0.174) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}
0.742 (+/-0.127) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.1}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 10, 'gamma': 0.2}
0.782 (+/-0.189) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.2}
0.756 (+/-0.174) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.2}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 10, 'gamma': 0.5}
0.777 (+/-0.202) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.5}
0.783 (+/-0.185) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.5}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 10, 'gamma': 1.0}
0.791 (+/-0.225) for {'kernel': 'rbf', 'C': 10, 'gamma': 1.0}
0.776 (+/-0.188) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 1.0}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 10, 'gamma': 10.0}
0.854 (+/-0.268) for {'kernel': 'rbf', 'C': 10, 'gamma': 10.0}
0.738 (+/-0.121) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 10.0}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 5, 'gamma': 0.05}
0.743 (+/-0.129) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.05}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.05}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 5, 'gamma': 0.1}
0.742 (+/-0.127) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.1}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.1}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 5, 'gamma': 0.2}
0.756 (+/-0.174) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.2}
0.742 (+/-0.127) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.2}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 5, 'gamma': 0.5}
0.780 (+/-0.195) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.5}
0.761 (+/-0.197) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.5}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 5, 'gamma': 1.0}
0.777 (+/-0.202) for {'kernel': 'rbf', 'C': 5, 'gamma': 1.0}
0.770 (+/-0.152) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 1.0}
0.780 (+/-0.195) for {'kernel': 'linear', 'C': 5, 'gamma': 10.0}
0.845 (+/-0.254) for {'kernel': 'rbf', 'C': 5, 'gamma': 10.0}
0.739 (+/-0.123) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 10.0}
0.742 (+/-0.127) for {'kernel': 'linear', 'C': 1, 'gamma': 0.05}
0.743 (+/-0.129) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.05}
0.742 (+/-0.127) for {'kernel': 'linear', 'C': 1, 'gamma': 0.1}
0.743 (+/-0.129) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.1}
0.742 (+/-0.127) for {'kernel': 'linear', 'C': 1, 'gamma': 0.2}
0.743 (+/-0.129) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.2}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.2}
0.742 (+/-0.127) for {'kernel': 'linear', 'C': 1, 'gamma': 0.5}
0.742 (+/-0.127) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.5}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.5}
0.742 (+/-0.127) for {'kernel': 'linear', 'C': 1, 'gamma': 1.0}
0.741 (+/-0.131) for {'kernel': 'rbf', 'C': 1, 'gamma': 1.0}
0.743 (+/-0.129) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 1.0}
0.742 (+/-0.127) for {'kernel': 'linear', 'C': 1, 'gamma': 10.0}
0.795 (+/-0.236) for {'kernel': 'rbf', 'C': 1, 'gamma': 10.0}
0.742 (+/-0.128) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 10.0}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.89      0.85      0.87        40
        1.0       0.00      0.00      0.00         4

avg / total       0.81      0.77      0.79        44

# GaussianNB :: Tuning parameters for recall
# Best parameters set found on training set:
{}
# Grid scores on testing set:
0.812 (+/-0.254) for {}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.90      0.93      0.91        40
        1.0       0.00      0.00      0.00         4

avg / total       0.82      0.84      0.83        44

# DecisionTreeClassifier :: Tuning parameters for recall
# Best parameters set found on training set:
{'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8}
# Grid scores on testing set:
0.871 (+/-0.224) for {'min_samples_split': 10, 'criterion': 'gini', 'max_depth': 8}
0.881 (+/-0.194) for {'min_samples_split': 6, 'criterion': 'gini', 'max_depth': 8}
0.871 (+/-0.256) for {'min_samples_split': 4, 'criterion': 'gini', 'max_depth': 8}
0.911 (+/-0.154) for {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8}
0.881 (+/-0.214) for {'min_samples_split': 10, 'criterion': 'gini', 'max_depth': 6}
0.871 (+/-0.205) for {'min_samples_split': 6, 'criterion': 'gini', 'max_depth': 6}
0.881 (+/-0.211) for {'min_samples_split': 4, 'criterion': 'gini', 'max_depth': 6}
0.891 (+/-0.206) for {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 6}
0.881 (+/-0.214) for {'min_samples_split': 10, 'criterion': 'gini', 'max_depth': 4}
0.871 (+/-0.205) for {'min_samples_split': 6, 'criterion': 'gini', 'max_depth': 4}
0.881 (+/-0.218) for {'min_samples_split': 4, 'criterion': 'gini', 'max_depth': 4}
0.881 (+/-0.218) for {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 4}
0.822 (+/-0.159) for {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 8}
0.871 (+/-0.211) for {'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 8}
0.871 (+/-0.267) for {'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': 8}
0.871 (+/-0.211) for {'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 8}
0.851 (+/-0.150) for {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 6}
0.891 (+/-0.161) for {'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 6}
0.861 (+/-0.254) for {'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': 6}
0.881 (+/-0.224) for {'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 6}
0.822 (+/-0.159) for {'min_samples_split': 10, 'criterion': 'entropy', 'max_depth': 4}
0.871 (+/-0.211) for {'min_samples_split': 6, 'criterion': 'entropy', 'max_depth': 4}
0.881 (+/-0.166) for {'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': 4}
0.871 (+/-0.267) for {'min_samples_split': 2, 'criterion': 'entropy', 'max_depth': 4}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.93      0.93      0.93        40
        1.0       0.25      0.25      0.25         4

avg / total       0.86      0.86      0.86        44

# LogisticRegression :: Tuning parameters for recall
# Best parameters set found on training set:
{'C': 1}
# Grid scores on testing set:
0.822 (+/-0.276) for {'C': 1000}
0.842 (+/-0.229) for {'C': 100}
0.842 (+/-0.159) for {'C': 10}
0.851 (+/-0.114) for {'C': 5}
0.861 (+/-0.075) for {'C': 1}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.91      1.00      0.95        40
        1.0       0.00      0.00      0.00         4

avg / total       0.83      0.91      0.87        44

# SVC :: Tuning parameters for recall
# Best parameters set found on training set:
{'kernel': 'rbf', 'C': 100, 'gamma': 0.5}
# Grid scores on testing set:
0.851 (+/-0.159) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.05}
0.851 (+/-0.229) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.05}
0.832 (+/-0.262) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.05}
0.851 (+/-0.159) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.1}
0.871 (+/-0.228) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.1}
0.832 (+/-0.208) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.1}
0.851 (+/-0.159) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.2}
0.881 (+/-0.197) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.2}
0.822 (+/-0.276) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.2}
0.851 (+/-0.159) for {'kernel': 'linear', 'C': 1000, 'gamma': 0.5}
0.842 (+/-0.210) for {'kernel': 'rbf', 'C': 1000, 'gamma': 0.5}
0.832 (+/-0.236) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 0.5}
0.851 (+/-0.159) for {'kernel': 'linear', 'C': 1000, 'gamma': 1.0}
0.842 (+/-0.192) for {'kernel': 'rbf', 'C': 1000, 'gamma': 1.0}
0.822 (+/-0.242) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 1.0}
0.851 (+/-0.159) for {'kernel': 'linear', 'C': 1000, 'gamma': 10.0}
0.871 (+/-0.243) for {'kernel': 'rbf', 'C': 1000, 'gamma': 10.0}
0.792 (+/-0.156) for {'kernel': 'sigmoid', 'C': 1000, 'gamma': 10.0}
0.842 (+/-0.210) for {'kernel': 'linear', 'C': 100, 'gamma': 0.05}
0.832 (+/-0.208) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}
0.842 (+/-0.159) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.05}
0.842 (+/-0.210) for {'kernel': 'linear', 'C': 100, 'gamma': 0.1}
0.832 (+/-0.208) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}
0.842 (+/-0.159) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.1}
0.842 (+/-0.210) for {'kernel': 'linear', 'C': 100, 'gamma': 0.2}
0.842 (+/-0.210) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.2}
0.822 (+/-0.260) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.2}
0.842 (+/-0.210) for {'kernel': 'linear', 'C': 100, 'gamma': 0.5}
0.891 (+/-0.209) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.5}
0.842 (+/-0.231) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 0.5}
0.842 (+/-0.210) for {'kernel': 'linear', 'C': 100, 'gamma': 1.0}
0.861 (+/-0.208) for {'kernel': 'rbf', 'C': 100, 'gamma': 1.0}
0.812 (+/-0.230) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 1.0}
0.842 (+/-0.210) for {'kernel': 'linear', 'C': 100, 'gamma': 10.0}
0.881 (+/-0.254) for {'kernel': 'rbf', 'C': 100, 'gamma': 10.0}
0.792 (+/-0.156) for {'kernel': 'sigmoid', 'C': 100, 'gamma': 10.0}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 10, 'gamma': 0.05}
0.851 (+/-0.080) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.05}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 10, 'gamma': 0.1}
0.851 (+/-0.080) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}
0.851 (+/-0.080) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.1}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 10, 'gamma': 0.2}
0.851 (+/-0.114) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.2}
0.851 (+/-0.080) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.2}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 10, 'gamma': 0.5}
0.832 (+/-0.208) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.5}
0.861 (+/-0.082) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 0.5}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 10, 'gamma': 1.0}
0.832 (+/-0.208) for {'kernel': 'rbf', 'C': 10, 'gamma': 1.0}
0.851 (+/-0.126) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 1.0}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 10, 'gamma': 10.0}
0.881 (+/-0.253) for {'kernel': 'rbf', 'C': 10, 'gamma': 10.0}
0.812 (+/-0.125) for {'kernel': 'sigmoid', 'C': 10, 'gamma': 10.0}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 5, 'gamma': 0.05}
0.861 (+/-0.075) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.05}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.05}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 5, 'gamma': 0.1}
0.851 (+/-0.080) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.1}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.1}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 5, 'gamma': 0.2}
0.851 (+/-0.080) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.2}
0.851 (+/-0.080) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.2}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 5, 'gamma': 0.5}
0.842 (+/-0.159) for {'kernel': 'rbf', 'C': 5, 'gamma': 0.5}
0.861 (+/-0.117) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 0.5}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 5, 'gamma': 1.0}
0.832 (+/-0.208) for {'kernel': 'rbf', 'C': 5, 'gamma': 1.0}
0.861 (+/-0.082) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 1.0}
0.842 (+/-0.159) for {'kernel': 'linear', 'C': 5, 'gamma': 10.0}
0.871 (+/-0.243) for {'kernel': 'rbf', 'C': 5, 'gamma': 10.0}
0.822 (+/-0.132) for {'kernel': 'sigmoid', 'C': 5, 'gamma': 10.0}
0.851 (+/-0.080) for {'kernel': 'linear', 'C': 1, 'gamma': 0.05}
0.861 (+/-0.075) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.05}
0.851 (+/-0.080) for {'kernel': 'linear', 'C': 1, 'gamma': 0.1}
0.861 (+/-0.075) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.1}
0.851 (+/-0.080) for {'kernel': 'linear', 'C': 1, 'gamma': 0.2}
0.861 (+/-0.075) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.2}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.2}
0.851 (+/-0.080) for {'kernel': 'linear', 'C': 1, 'gamma': 0.5}
0.851 (+/-0.080) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.5}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 0.5}
0.851 (+/-0.080) for {'kernel': 'linear', 'C': 1, 'gamma': 1.0}
0.842 (+/-0.109) for {'kernel': 'rbf', 'C': 1, 'gamma': 1.0}
0.861 (+/-0.075) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 1.0}
0.851 (+/-0.080) for {'kernel': 'linear', 'C': 1, 'gamma': 10.0}
0.842 (+/-0.231) for {'kernel': 'rbf', 'C': 1, 'gamma': 10.0}
0.851 (+/-0.089) for {'kernel': 'sigmoid', 'C': 1, 'gamma': 10.0}
Detailed classification report on the test set:
             precision    recall  f1-score   support

        0.0       0.89      0.85      0.87        40
        1.0       0.00      0.00      0.00         4

avg / total       0.81      0.77      0.79        44

For optimum precision :
   GaussianNB :   0.763 with parameters {}
   DecisionTreeClassifier :   0.905 with parameters {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8}
   LogisticRegression :   0.807 with parameters {'C': 100}
   SVC :   0.894 with parameters {'kernel': 'rbf', 'C': 100, 'gamma': 0.5}
For optimum recall :
   GaussianNB :   0.812 with parameters {}
   DecisionTreeClassifier :   0.911 with parameters {'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 8}
   LogisticRegression :   0.861 with parameters {'C': 1}
   SVC :   0.891 with parameters {'kernel': 'rbf', 'C': 100, 'gamma': 0.5}
